# OneHotEncoder

## 什么是one-hot code
假如有三种颜色特征：红、黄、蓝。 在利用机器学习的算法时一般需要进行向量化或者数字化。
那么你可能想令 红=1，黄=2，蓝=3. 那么这样其实实现了标签编码，即给不同类别以标签。
然而这意味着机器可能会学习到“红<黄<蓝”，但这并不是我们的让机器学习的本意，只是想让机器区分它们，并无大小比较之意。
所以这时标签编码是不够的，需要进一步转换。因为有三种颜色状态，所以就有3个比特。即红色：1 0 0 ，黄色: 0 1 0，蓝色：0 0 1 。
如此一来每两个向量之间的距离都是根号2，在向量空间距离都相等，所以这样不会出现偏序性，基本不会影响基于向量空间度量算法的效果。

## 为什么用 one-hot code

为了使非偏序关系的变量取值不具有偏序性，并且到圆点是等距的。

解释：使用one-hot编码，将离散特征的取值扩展到了欧式空间，离散特征的某个取值就对应欧式空间的某个点。
     离散特征进行one-hot编码后，可以看做是连续的特征。
     就可以跟对连续型特征的归一化方法一样，对每一维特征进行归一化。
     比如归一化到[-1,1]或归一化到均值为0,方差为1。       

### 为什么特征向量要映射到欧式空间？

在回归，分类，聚类等机器学习算法中，特征之间距离的计算或相似度的计算是非常重要的，
而我们常用的距离或相似度的计算都是在欧式空间的相似度计算，计算余弦相似性，基于的就是欧式空间。


## one-hot code优缺点

优点：独热编码解决了分类器不好处理属性数据的问题，在一定程度上也起到了扩充特征的作用。它的值只有0和1，不同的类型存储在垂直的空间。
缺点：当类别的数量很多时，特征空间会变得非常大。在这种情况下，一般可以用PCA来减少维度。
     而且one hot encoding+PCA这种组合在实际中也非常有用。
 
## 什么情况下用独热编码？

用：独热编码用来解决类别型数据的离散值问题（为了让距离计算更合理）

不用：特征是离散的，并且不用one-hot编码就可以很合理的计算出距离。 
     有些基于树的算法在处理变量时，数值只是个类别符号，即没有偏序关系，所以不用进行独热编码。  
     Tree Model不太需要one-hot编码： 对于决策树来说，one-hot的本质是增加树的深度。

 
## 什么情况下需要归一化？

需要： 基于参数的模型或基于距离的模型，都是要进行特征的归一化。
不需要：基于树的方法是不需要进行特征的归一化，例如随机森林，bagging 和 boosting等。


补充说明：

1.特征类别：连续型特征和离散型特征

2.拿到获取的原始特征，必须对每一特征分别进行归一化，比如，特征A的取值范围是[-1000,1000]，特征B的取值范围是[-1,1].
如果使用logistic回归，w1*x1+w2*x2，因为x1的取值太大了，所以x2基本起不了作用。所以，必须进行特征的归一化，每个特征都单独进行归一化。

3.对于连续性特征：
  3.1.Rescale bounded continuous features  线性放缩到[-1,1]
  3.2.Standardize 均值为0，方差为1
  3.3.Binarize categorical/discrete features one-hot（独热）编码，该离散特征有多少取值，就用多少维来表示该特征
  
  
Reference： 
1. Blog.csdn.net. 2020. 数据挖掘onehotencoder独热编码和labelencoder标签编码_这里记录着我一点一滴的进步-CSDN博客_标签编码 Label Encoder. 
  [online] Available at: <https://blog.csdn.net/ccblogger/article/details/80010974> [Accessed 29 June 2020].
