Lasso回归

Lasso回归与岭回归非常相似，因为两种技术都有相同的前提：它们都是在回归优化函数中增加一个偏置项，以减少共线性的影响，从而减少模型方差。然而，不像岭回归那样使用平方偏差，Lasso回归使用绝对值偏差作为正则化项：

岭回归和Lasso回归之间存在一些差异，基本上可以归结为L2和L1正则化的性质差异：

• 内置的特征选择（Built-in feature selection）：这是L1范数的一个非常有用的属性，而L2范数不具有这种特性。这实际上因为是L1范数倾向于产生稀疏系数。例如，假设模型有100个系数，但其中只有10个系数是非零系数，这实际上是说“其他90个变量对预测目标值没有用处”。 而L2范数产生非稀疏系数，所以没有这个属性。因此，可以说Lasso回归做了一种“参数选择”形式，未被选中的特征变量对整体的权重为0。

• 稀疏性：指矩阵（或向量）中只有极少数条目非零。 L1范数具有产生具有零值或具有很少大系数的非常小值的许多系数的属性。

• 计算效率：L1范数没有解析解，但L2范数有。这使得L2范数的解可以通过计算得到。然而，L1范数的解具有稀疏性，这使得它可以与稀疏算法一起使用，这使得在计算上更有效率。

Reference
1.https://www.sohu.com/a/249214202_814235
